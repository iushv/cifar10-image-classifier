{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Image Classification with CNN\n",
    "\n",
    "This notebook demonstrates how to build and train a Convolutional Neural Network (CNN) to classify images from the CIFAR-10 dataset.\n",
    "\n",
    "**CIFAR-10 Dataset:**\n",
    "- 60,000 32x32 color images in 10 classes\n",
    "- 50,000 training images and 10,000 test images\n",
    "- Classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Define class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Training images shape: {train_images.shape}\")\n",
    "print(f\"Training labels shape: {train_labels.shape}\")\n",
    "print(f\"Test images shape: {test_images.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")\n",
    "print(f\"\\nNumber of training samples: {len(train_images)}\")\n",
    "print(f\"Number of test samples: {len(test_images)}\")\n",
    "print(f\"Image dimensions: {train_images.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 25 images from the training set\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i])\n",
    "    plt.xlabel(class_names[train_labels[i][0]], fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "print(\"Data normalized successfully!\")\n",
    "print(f\"Training data range: [{train_images.min()}, {train_images.max()}]\")\n",
    "print(f\"Test data range: [{test_images.min()}, {test_images.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the CNN Model\n",
    "\n",
    "We'll create a Convolutional Neural Network with:\n",
    "- 3 Convolutional layers with ReLU activation\n",
    "- MaxPooling layers for downsampling\n",
    "- Dropout for regularization\n",
    "- Dense layers for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "        # First Convolutional Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Dense Layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')  # 10 classes\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_model()\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Set Up Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Reduce learning rate when validation loss plateaus\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, \n",
    "    train_labels,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy and loss\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "ax1.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "ax2.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "ax2.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Loss', fontsize=12)\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=2)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Make Predictions on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# Function to display predictions\n",
    "def plot_predictions(images, true_labels, predictions, class_names, num_images=15):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(3, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i])\n",
    "        \n",
    "        predicted_label = np.argmax(predictions[i])\n",
    "        true_label = true_labels[i][0]\n",
    "        confidence = 100 * np.max(predictions[i])\n",
    "        \n",
    "        # Color code: green for correct, red for incorrect\n",
    "        color = 'green' if predicted_label == true_label else 'red'\n",
    "        \n",
    "        plt.xlabel(f\"Pred: {class_names[predicted_label]}\\nTrue: {class_names[true_label]}\\nConf: {confidence:.1f}%\",\n",
    "                   color=color, fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display predictions\n",
    "plot_predictions(test_images, test_labels, predictions, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Get predicted classes\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_labels.flatten()\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Per-Class Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-class accuracy\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(class_names, class_accuracy * 100, color='steelblue', edgecolor='black', linewidth=1.2)\n",
    "\n",
    "# Color bars based on accuracy\n",
    "for i, bar in enumerate(bars):\n",
    "    if class_accuracy[i] >= 0.8:\n",
    "        bar.set_color('green')\n",
    "    elif class_accuracy[i] >= 0.6:\n",
    "        bar.set_color('orange')\n",
    "    else:\n",
    "        bar.set_color('red')\n",
    "\n",
    "plt.xlabel('Class', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "plt.title('Per-Class Accuracy', fontsize=14, fontweight='bold', pad=15)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0, 100)\n",
    "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (name, acc) in enumerate(zip(class_names, class_accuracy)):\n",
    "    plt.text(i, acc * 100 + 2, f'{acc*100:.1f}%', ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print per-class accuracy\n",
    "print(\"\\nPer-Class Accuracy:\")\n",
    "print(\"=\"*40)\n",
    "for name, acc in zip(class_names, class_accuracy):\n",
    "    print(f\"{name:12s}: {acc*100:6.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('cifar10_cnn_model.h5')\n",
    "print(\"Model saved as 'cifar10_cnn_model.h5'\")\n",
    "\n",
    "# Also save in TensorFlow SavedModel format\n",
    "model.save('cifar10_cnn_model')\n",
    "print(\"Model saved as 'cifar10_cnn_model' (SavedModel format)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Test with Custom Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict a single image\n",
    "def predict_single_image(model, image, true_label=None):\n",
    "    # Add batch dimension\n",
    "    img_array = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(img_array, verbose=0)\n",
    "    predicted_class = np.argmax(prediction[0])\n",
    "    confidence = np.max(prediction[0]) * 100\n",
    "    \n",
    "    # Display image and prediction\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    title = f\"Predicted: {class_names[predicted_class]} ({confidence:.2f}%)\"\n",
    "    if true_label is not None:\n",
    "        title += f\"\\nTrue: {class_names[true_label]}\"\n",
    "        color = 'green' if predicted_class == true_label else 'red'\n",
    "    else:\n",
    "        color = 'blue'\n",
    "    \n",
    "    plt.title(title, fontsize=14, fontweight='bold', color=color)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top 3 predictions\n",
    "    top_3_indices = np.argsort(prediction[0])[-3:][::-1]\n",
    "    print(\"\\nTop 3 Predictions:\")\n",
    "    print(\"=\"*40)\n",
    "    for i, idx in enumerate(top_3_indices, 1):\n",
    "        print(f\"{i}. {class_names[idx]:12s}: {prediction[0][idx]*100:6.2f}%\")\n",
    "\n",
    "# Test with a random image from test set\n",
    "random_idx = np.random.randint(0, len(test_images))\n",
    "predict_single_image(model, test_images[random_idx], test_labels[random_idx][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. ✅ Loading and exploring the CIFAR-10 dataset\n",
    "2. ✅ Data preprocessing and normalization\n",
    "3. ✅ Building a CNN architecture with batch normalization and dropout\n",
    "4. ✅ Training with callbacks (early stopping, learning rate reduction)\n",
    "5. ✅ Visualizing training history\n",
    "6. ✅ Evaluating model performance\n",
    "7. ✅ Analyzing predictions with confusion matrix\n",
    "8. ✅ Per-class accuracy analysis\n",
    "9. ✅ Saving the trained model\n",
    "\n",
    "**Expected Performance:** With this architecture, you should achieve around 75-85% accuracy on the test set.\n",
    "\n",
    "**Next Steps:**\n",
    "- Try data augmentation to improve accuracy\n",
    "- Experiment with different architectures (ResNet, VGG, etc.)\n",
    "- Use transfer learning with pre-trained models\n",
    "- Implement learning rate scheduling\n",
    "- Try ensemble methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
